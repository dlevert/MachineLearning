---
title: "Machine Learning Assignment"
author: "Denis Levert on November 11, 2020"
output: html_document
---

## Executive Summary

This report is written as an assignment for practicle machine learning.
The data is from (and owned by) http://groupware.les.inf.puc-rio.br/har. 
The data for this report is as follows:

1) Training Set - https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
2) Test Set - https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The purpose of this report is to fit the most accurate data model to predict the test set.

```{r setup, include=FALSE, cache=TRUE}
     knitr::opts_chunk$set(echo = TRUE)
     require(knitr)
     require(caret)
     require(ggplot2)
     training <- read.csv(
          "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
     testing <- read.csv(
          "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
     trainSub <- training
     trainSub <- trainSub[,-1]
     trainSub <- trainSub[,-2:-6]
     trainSub[trainSub == ""] <- NA
     trainSub <- trainSub[, colSums(is.na(trainSub))==0]
     trainSub[, 2:53] <- apply(trainSub[,2:53], 2, as.numeric)
     trainSub$user_name <- as.factor(trainSub$user_name)
     trainSub$classe <- as.factor(trainSub$classe)
     testSub <- testing
     testSub <- testSub[,-1]
     testSub <- testSub[,-2:-6]
     testSub[testSub == ""] <- NA
     testSub <- testSub[, colSums(is.na(testSub))==0]
     testSub[, 2:53] <- apply(testSub[,2:53], 2, as.numeric)
     testSub <- testSub[,-54]
     testSub$user_name <- as.factor(testSub$user_name)
     rm(training); rm(testing)
```

## Cleaning and Modelling
 The data has a substantial amount of columns with blank or NA values, as well as unused columns. The first step was to subset this data and remove these columns. The next step was to correctly set numbers as numeric, classe to factor and user_name to factor. This was done on both the training and test sets.
 
 I selected 3 methods to initially model the data:
 
 1) Random Forest
 2) Boosted Regression
 3) Linear Discriminant Analysis

The modelling takes a lot of computation time.

```{r explore, message=FALSE, comment=FALSE, echo=FALSE, cache=TRUE}
     set.seed(333)
     modFit1 <- train(classe ~ ., data = trainSub, method="rf", ntree=100)
     modFit2 <- train(classe ~ ., data = trainSub, method = "gbm",
                      verbose = FALSE)
     modFit3 <- train(classe ~ ., data = trainSub, method = "lda")
     pdRF <- predict(modFit1, newdata = testSub)
     pdGBM <- predict(modFit1, newdata = testSub)
     pdLDA <- predict(modFit1, newdata = testSub)
```

## Variable Importance

The variables in order of importance are:

```{r var, echo=FALSE, cache=TRUE}
     require(kableExtra)
     modComp <- data.frame(pdRF, pdGBM, pdLDA)
     impRF <- varImp(modFit1)
     impRF <- data.frame(impRF$importance)
     impRF$Variable <- rownames(impRF)
     impRF <- impRF[order(impRF$Overall, decreasing = TRUE),]
     impRF$Overall <- round(impRF$Overall,1)
     impRF$Importance <- 1:dim(impRF)[1]
     impRF[1:10,c(3,2,1)] %>% kbl(row.names = FALSE, 
                                  align = c("c","l", "c")) %>%
     kable_classic_2(full_width = T)

```

## Model Comparison

I then ran a prediction of the models and plotted the results:

```{r plots, echo=FALSE, cache=TRUE, tidy=TRUE}
     par(mfcol = c(1,3))
     plot(modComp$pdRF, main = "Random Forest Prediction", col = "blue")
     plot(modComp$pdGBM, main = "Boosted Regression Prediction", col = "green")
     plot(modComp$pdLDA, main = "Linear Discriminant Predistion", col = "brown")
     rownames(modComp) <- 1:20
     t <- t(modComp)
     t %>% kbl() %>% kable_classic_2(full_width = T)
```

The plots and the table both indicate the models are predicting the same results.

## Accuracy

To narrow the results, I will look at the accuracy of the models.

```{r accuracy, echo=FALSE, cache=FALSE}
     print(paste("Random Forest Accuracy", 
                 round(modFit1$results[2,2]*100,2), "%"))
     print(paste("Boosted Regression Accuracy", 
                 round(modFit2$results[9,5]*100,2), "%"))
     print(paste("Linear Discriminant Accuracy", 
                 round(modFit3$results[1,2]*100,2), "%"))
```

The selected model will be the Random Forest with an accuracy of 99.3% is the most accurate and will be used for prediction.

## Prediction Model

The Random Forest confusion matrix is as follows:

```{r plot, echo=FALSE, message=FALSE}
     require(kableExtra)
     modFit1$finalModel$confusion %>% kbl() %>% kable_classic_2(full_width = T)
```

## Selected Model

The predictions using the Random Forest method are:

```{r concl, echo=FALSE}
u <- t(data.frame(t[1,]))
rownames(u) <- "Random Forest"
u %>% kbl() %>% kable_classic_2(full_width = T)
```

## Conclusion

The model appears to be able to predict the outcomes of the test dataset at an accuracy of 99.3%. I believe this can accurately predict the classe variable in future datasets.